{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dac5e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLEANING CUSTOMER DATA\n",
      "============================================================\n",
      "\n",
      "Original data shape: (9, 2)\n",
      "\n",
      "First few rows:\n",
      "   Customer ID   Customer Name\n",
      "0          1.0        Jane Doe\n",
      "1          2.0      John Smith\n",
      "2          3.0      Dan Reeves\n",
      "3          NaN             NaN\n",
      "4          5.0  William Holden\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CLEANING CUSTOMER DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Read the Customer CSV file\n",
    "df_customers = pd.read_csv('C:/Users/Admin/Desktop/M5-20260106/sample-data/03_Library SystemCustomers.csv')\n",
    "\n",
    "print(\"\\nOriginal data shape:\", df_customers.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df_customers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "647bc388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Missing Values Check ---\n",
      "Customer ID      1\n",
      "Customer Name    1\n",
      "dtype: int64\n",
      "Total rows with missing values: 1\n",
      "\n",
      "--- Converting Customer ID to Integer ---\n",
      "Customer ID converted to integer\n",
      "\n",
      "After removing all missing values: (8, 2)\n",
      "\n",
      "--- Duplicate Check ---\n",
      "Number of duplicate rows: 0\n",
      "After removing duplicates: (8, 2)\n",
      "\n",
      "--- Standardizing Column Names ---\n",
      "New column names: ['Customer_Id', 'Customer_Name']\n",
      "\n",
      "--- Customer Data Cleaning Summary ---\n",
      "Original rows: 8\n",
      "Rows removed (missing values): 0\n",
      "Rows removed (duplicates): 0\n",
      "Final rows: 8\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\n--- Missing Values Check ---\")\n",
    "missing_count = df_customers.isnull().sum()\n",
    "print(missing_count)\n",
    "print(f\"Total rows with missing values: {df_customers.isnull().any(axis=1).sum()}\")\n",
    "\n",
    "# Convert Customer ID to integer (before removing other missing values)\n",
    "print(\"\\n--- Converting Customer ID to Integer ---\")\n",
    "# First, remove rows where Customer ID is missing\n",
    "df_customers = df_customers.dropna(subset=['Customer ID'])\n",
    "df_customers['Customer ID'] = df_customers['Customer ID'].astype(int)\n",
    "print(\"Customer ID converted to integer\")\n",
    "\n",
    "# Remove rows with missing values in any column\n",
    "df_customers_cleaned = df_customers.dropna()\n",
    "print(f\"\\nAfter removing all missing values: {df_customers_cleaned.shape}\")\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"\\n--- Duplicate Check ---\")\n",
    "duplicate_count = df_customers_cleaned.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "\n",
    "# Remove duplicates\n",
    "df_customers_cleaned = df_customers_cleaned.drop_duplicates()\n",
    "print(f\"After removing duplicates: {df_customers_cleaned.shape}\")\n",
    "\n",
    "# Standardize column names (capitalize first letter, replace spaces with _)\n",
    "print(\"\\n--- Standardizing Column Names ---\")\n",
    "df_customers_cleaned.columns = df_customers_cleaned.columns.str.replace(' ', '_').str.title()\n",
    "print(f\"New column names: {list(df_customers_cleaned.columns)}\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n--- Customer Data Cleaning Summary ---\")\n",
    "print(f\"Original rows: {len(df_customers)}\")\n",
    "print(f\"Rows removed (missing values): {len(df_customers) - len(df_customers.dropna())}\")\n",
    "print(f\"Rows removed (duplicates): {len(df_customers.dropna()) - len(df_customers_cleaned)}\")\n",
    "print(f\"Final rows: {len(df_customers_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe5e39bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned customer data saved to 'output-data/cleaned_customers.csv'\n",
      "\n",
      "============================================================\n",
      "CLEANING LIBRARY SYSTEM DATA\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned customer data\n",
    "df_customers_cleaned.to_csv('output-data/cleaned_customers.csv', index=False)\n",
    "print(\"\\nCleaned customer data saved to 'output-data/cleaned_customers.csv'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLEANING LIBRARY SYSTEM DATA\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d9307bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLEANING LIBRARY SYSTEM DATA\n",
      "============================================================\n",
      "\n",
      "Original data shape: (114, 6)\n",
      "\n",
      "First few rows:\n",
      "    Id                                     Books Book checkout Book Returned  \\\n",
      "0  1.0                       Catcher in the Rye   \"20/02/2023\"    25/02/2023   \n",
      "1  2.0          Lord of the rings the two towers  \"24/03/2023\"    21/03/2023   \n",
      "2  3.0  Lord of the rings the return of the kind  \"29/03/2023\"    25/03/2023   \n",
      "3  4.0                                The hobbit  \"02/04/2023\"    25/03/2023   \n",
      "4  5.0                                     Dune   \"02/04/2023\"    25/03/2023   \n",
      "\n",
      "  Days allowed to borrow  Customer ID  \n",
      "0                2 weeks          1.0  \n",
      "1                2 weeks          2.0  \n",
      "2                2 weeks          3.0  \n",
      "3                2 weeks          4.0  \n",
      "4                2 weeks          5.0  \n",
      "\n",
      "Data types:\n",
      "Id                        float64\n",
      "Books                      object\n",
      "Book checkout              object\n",
      "Book Returned              object\n",
      "Days allowed to borrow     object\n",
      "Customer ID               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLEANING LIBRARY SYSTEM DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Read the Library System CSV file\n",
    "df_library = pd.read_csv('C:/Users/Admin/Desktop/M5-20260106/sample-data/03_Library Systembook.csv')\n",
    "\n",
    "print(\"\\nOriginal data shape:\", df_library.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df_library.head())\n",
    "print(\"\\nData types:\")\n",
    "print(df_library.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526bb7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Missing Values Check ---\n",
      "Id                        93\n",
      "Books                     94\n",
      "Book checkout             93\n",
      "Book Returned             93\n",
      "Days allowed to borrow    93\n",
      "Customer ID               94\n",
      "dtype: int64\n",
      "Total rows with missing values: 94\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\n--- Missing Values Check ---\")\n",
    "missing_count = df_library.isnull().sum()\n",
    "print(missing_count)\n",
    "print(f\"Total rows with missing values: {df_library.isnull().any(axis=1).sum()}\")\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_library_cleaned = df_library.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e51b74ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Standardizing Column Names ---\n",
      "Original column names: ['Id', 'Books', 'Book checkout', 'Book Returned', 'Days allowed to borrow', 'Customer ID']\n",
      "New column names: ['Id', 'Books', 'Book_Checkout', 'Book_Returned', 'Days_Allowed_To_Borrow', 'Customer_Id']\n",
      "\n",
      "--- Cleaning Book Titles ---\n",
      "Book titles cleaned and formatted\n",
      "Sample book titles:\n",
      "0                          Catcher In The Rye\n",
      "1            Lord Of The Rings The Two Towers\n",
      "2    Lord Of The Rings The Return Of The Kind\n",
      "3                                  The Hobbit\n",
      "4                                        Dune\n",
      "Name: Books, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Standardize column names first (capitalize first letter, replace spaces with _)\n",
    "print(\"\\n--- Standardizing Column Names ---\")\n",
    "print(f\"Original column names: {list(df_library_cleaned.columns)}\")\n",
    "df_library_cleaned.columns = df_library_cleaned.columns.str.replace(' ', '_').str.title()\n",
    "print(f\"New column names: {list(df_library_cleaned.columns)}\")\n",
    "\n",
    "# Clean book titles: remove trailing spaces, title case\n",
    "print(\"\\n--- Cleaning Book Titles ---\")\n",
    "if 'Books' in df_library_cleaned.columns:\n",
    "    # Remove leading/trailing spaces\n",
    "    df_library_cleaned['Books'] = df_library_cleaned['Books'].str.strip()\n",
    "    \n",
    "    # Convert to title case (capitalizes major words, lowercase for minor words)\n",
    "    df_library_cleaned['Books'] = df_library_cleaned['Books'].str.title()\n",
    "    print(\"Book titles cleaned and formatted\")\n",
    "    print(\"Sample book titles:\")\n",
    "    print(df_library_cleaned['Books'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae0e7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Removing Quotation Marks from Dates ---\n",
      "Quotation marks removed from Book_Checkout column\n",
      "\n",
      "--- Converting Weeks to Days ---\n",
      "Warning: Found 93 rows that couldn't be converted to days\n",
      "These rows will be removed\n",
      "Converted weeks to days\n",
      "Sample values: [14, 14, 14, 14, 14]\n"
     ]
    }
   ],
   "source": [
    "# Remove quotation marks from Book_Checkout dates\n",
    "print(\"\\n--- Removing Quotation Marks from Dates ---\")\n",
    "if 'Book_Checkout' in df_library_cleaned.columns:\n",
    "    df_library_cleaned['Book_Checkout'] = df_library_cleaned['Book_Checkout'].astype(str).str.replace('\"', '').str.replace(\"'\", '')\n",
    "    print(\"Quotation marks removed from Book_Checkout column\")\n",
    "\n",
    "# Convert \"2 weeks\" to days (14 days)\n",
    "print(\"\\n--- Converting Weeks to Days ---\")\n",
    "if 'Days_Allowed_To_Borrow' in df_library_cleaned.columns:\n",
    "    # Handle \"2 weeks\" or similar patterns\n",
    "    df_library_cleaned['Days_Allowed_To_Borrow'] = df_library_cleaned['Days_Allowed_To_Borrow'].astype(str).str.lower()\n",
    "    df_library_cleaned['Days_Allowed_To_Borrow'] = df_library_cleaned['Days_Allowed_To_Borrow'].str.replace('weeks', '').str.strip()\n",
    "    df_library_cleaned['Days_Allowed_To_Borrow'] = pd.to_numeric(df_library_cleaned['Days_Allowed_To_Borrow'], errors='coerce') * 7\n",
    "    \n",
    "    # Check for any NaN values after conversion\n",
    "    invalid_days_count = df_library_cleaned['Days_Allowed_To_Borrow'].isnull().sum()\n",
    "    if invalid_days_count > 0:\n",
    "        print(f\"Warning: Found {invalid_days_count} rows that couldn't be converted to days\")\n",
    "        print(\"These rows will be removed\")\n",
    "        df_library_cleaned = df_library_cleaned.dropna(subset=['Days_Allowed_To_Borrow'])\n",
    "    \n",
    "    # Now convert to integer\n",
    "    df_library_cleaned['Days_Allowed_To_Borrow'] = df_library_cleaned['Days_Allowed_To_Borrow'].astype(int)\n",
    "    print(\"Converted weeks to days\")\n",
    "    print(f\"Sample values: {df_library_cleaned['Days_Allowed_To_Borrow'].head().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e25db59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Date Format Check ---\n",
      "\n",
      "Processing column: Book_Checkout\n",
      "  Found 1 rows with invalid date format\n",
      "\n",
      "Processing column: Book_Returned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16636\\1658277173.py:12: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_library_cleaned[col] = pd.to_datetime(df_library_cleaned[col], errors='coerce')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16636\\1658277173.py:12: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_library_cleaned[col] = pd.to_datetime(df_library_cleaned[col], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime format and check for incorrect formats\n",
    "print(\"\\n--- Date Format Check ---\")\n",
    "date_columns = ['Book_Checkout', 'Book_Returned']\n",
    "\n",
    "for col in date_columns:\n",
    "    if col in df_library_cleaned.columns:\n",
    "        print(f\"\\nProcessing column: {col}\")\n",
    "        # Count nulls before conversion\n",
    "        nulls_before = df_library_cleaned[col].isnull().sum()\n",
    "        \n",
    "        # Try to convert to datetime, coerce errors to NaT\n",
    "        df_library_cleaned[col] = pd.to_datetime(df_library_cleaned[col], errors='coerce')\n",
    "        \n",
    "        # Check how many invalid dates were found\n",
    "        nulls_after = df_library_cleaned[col].isnull().sum()\n",
    "        invalid_dates = nulls_after - nulls_before\n",
    "        if invalid_dates > 0:\n",
    "            print(f\"  Found {invalid_dates} rows with invalid date format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1718655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Days Allowed to Borrow Check ---\n",
      "Rows with invalid days (<=0): 0\n",
      "\n",
      "--- Logical Consistency Check ---\n",
      "Rows where checkout date is after return date: 6\n",
      "Sample rows with date issues:\n",
      "    Id Book_Checkout Book_Returned\n",
      "1  2.0    2023-03-24    2023-03-21\n",
      "2  3.0    2023-03-29    2023-03-25\n",
      "3  4.0    2023-04-02    2023-03-25\n",
      "4  5.0    2023-04-02    2023-03-25\n",
      "6  7.0    2063-04-10    2023-04-03\n"
     ]
    }
   ],
   "source": [
    "# Check for negative or zero values in 'Days_Allowed_To_Borrow'\n",
    "print(\"\\n--- Days Allowed to Borrow Check ---\")\n",
    "if 'Days_Allowed_To_Borrow' in df_library_cleaned.columns:\n",
    "    invalid_days = df_library_cleaned['Days_Allowed_To_Borrow'] <= 0\n",
    "    print(f\"Rows with invalid days (<=0): {invalid_days.sum()}\")\n",
    "    if invalid_days.sum() > 0:\n",
    "        print(\"Sample invalid values:\")\n",
    "        print(df_library_cleaned[invalid_days][['Id', 'Days_Allowed_To_Borrow']].head())\n",
    "\n",
    "# Check for logical inconsistencies (checkout date after return date)\n",
    "print(\"\\n--- Logical Consistency Check ---\")\n",
    "if 'Book_Checkout' in df_library_cleaned.columns and 'Book_Returned' in df_library_cleaned.columns:\n",
    "    date_issue = df_library_cleaned['Book_Checkout'] > df_library_cleaned['Book_Returned']\n",
    "    date_issue = date_issue.fillna(False)\n",
    "    print(f\"Rows where checkout date is after return date: {date_issue.sum()}\")\n",
    "    if date_issue.sum() > 0:\n",
    "        print(\"Sample rows with date issues:\")\n",
    "        print(df_library_cleaned[date_issue][['Id', 'Book_Checkout', 'Book_Returned']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e41533e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Removing Rows with Missing Values ---\n",
      "Removed 2 rows with missing values\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing values in critical columns\n",
    "print(\"\\n--- Removing Rows with Missing Values ---\")\n",
    "rows_before = len(df_library_cleaned)\n",
    "df_library_cleaned = df_library_cleaned.dropna()\n",
    "rows_after = len(df_library_cleaned)\n",
    "print(f\"Removed {rows_before - rows_after} rows with missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d05a9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Converting Customer_Id to Integer ---\n",
      "Customer_Id converted to integer\n",
      "\n",
      "--- Converting Id to Integer ---\n",
      "Id converted to integer\n"
     ]
    }
   ],
   "source": [
    "# Convert Customer_Id to integer\n",
    "print(\"\\n--- Converting Customer_Id to Integer ---\")\n",
    "if 'Customer_Id' in df_library_cleaned.columns:\n",
    "    # First check if there are any missing values\n",
    "    missing_customer_ids = df_library_cleaned['Customer_Id'].isnull().sum()\n",
    "    if missing_customer_ids > 0:\n",
    "        print(f\"Warning: Found {missing_customer_ids} missing Customer_Id values\")\n",
    "        print(\"Removing rows with missing Customer_Id...\")\n",
    "        df_library_cleaned = df_library_cleaned.dropna(subset=['Customer_Id'])\n",
    "    \n",
    "    # Now convert to integer\n",
    "    df_library_cleaned['Customer_Id'] = df_library_cleaned['Customer_Id'].astype(int)\n",
    "    print(\"Customer_Id converted to integer\")\n",
    "\n",
    "# Convert Id to integer\n",
    "print(\"\\n--- Converting Id to Integer ---\")\n",
    "if 'Id' in df_library_cleaned.columns:\n",
    "    # First check if there are any missing values\n",
    "    missing_ids = df_library_cleaned['Id'].isnull().sum()\n",
    "    if missing_ids > 0:\n",
    "        print(f\"Warning: Found {missing_ids} missing Id values\")\n",
    "        print(\"Removing rows with missing Id...\")\n",
    "        df_library_cleaned = df_library_cleaned.dropna(subset=['Id'])\n",
    "    \n",
    "    # Now convert to integer\n",
    "    df_library_cleaned['Id'] = df_library_cleaned['Id'].astype(int)\n",
    "    print(\"Id converted to integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed8fc5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Duplicate Check ---\n",
      "Number of duplicate rows: 0\n",
      "After removing duplicates: (19, 6)\n",
      "\n",
      "--- Duplicate ID Check ---\n",
      "Number of duplicate IDs: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(\"\\n--- Duplicate Check ---\")\n",
    "duplicate_count = df_library_cleaned.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    print(\"Sample duplicate rows:\")\n",
    "    print(df_library_cleaned[df_library_cleaned.duplicated(keep=False)].head())\n",
    "\n",
    "# Remove duplicates\n",
    "df_library_cleaned = df_library_cleaned.drop_duplicates()\n",
    "print(f\"After removing duplicates: {df_library_cleaned.shape}\")\n",
    "\n",
    "# Check for duplicate IDs (if ID should be unique)\n",
    "print(\"\\n--- Duplicate ID Check ---\")\n",
    "if 'Id' in df_library_cleaned.columns:\n",
    "    duplicate_ids = df_library_cleaned['Id'].duplicated().sum()\n",
    "    print(f\"Number of duplicate IDs: {duplicate_ids}\")\n",
    "    if duplicate_ids > 0:\n",
    "        print(\"IDs that appear multiple times:\")\n",
    "        print(df_library_cleaned[df_library_cleaned['Id'].duplicated(keep=False)].sort_values('Id')[['Id', 'Books']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdc1eb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Library Data Cleaning Summary ---\n",
      "Original rows: 114\n",
      "Rows with invalid date formats: 0\n",
      "Rows removed (missing values): 2\n",
      "Rows removed (duplicates): 0\n",
      "Final rows: 19\n"
     ]
    }
   ],
   "source": [
    "# Display summary\n",
    "print(\"\\n--- Library Data Cleaning Summary ---\")\n",
    "print(f\"Original rows: {len(df_library)}\")\n",
    "print(f\"Rows with invalid date formats: {invalid_dates if 'invalid_dates' in locals() else 0}\")\n",
    "print(f\"Rows removed (missing values): {rows_before - rows_after}\")\n",
    "print(f\"Rows removed (duplicates): {duplicate_count}\")\n",
    "print(f\"Final rows: {len(df_library_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28f68135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned library data saved to 'output-data/cleaned_library_systembook.csv'\n",
      "\n",
      "First few rows of cleaned library data:\n",
      "   Id                                     Books Book_Checkout Book_Returned  \\\n",
      "0   1                        Catcher In The Rye    2023-02-20    2023-02-25   \n",
      "1   2          Lord Of The Rings The Two Towers    2023-03-24    2023-03-21   \n",
      "2   3  Lord Of The Rings The Return Of The Kind    2023-03-29    2023-03-25   \n",
      "3   4                                The Hobbit    2023-04-02    2023-03-25   \n",
      "4   5                                      Dune    2023-04-02    2023-03-25   \n",
      "\n",
      "   Days_Allowed_To_Borrow  Customer_Id  \n",
      "0                      14            1  \n",
      "1                      14            2  \n",
      "2                      14            3  \n",
      "3                      14            4  \n",
      "4                      14            5  \n",
      "\n",
      "============================================================\n",
      "CLEANING COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned library data\n",
    "df_library_cleaned.to_csv('output-data/cleaned_library_systembook.csv', index=False)\n",
    "print(\"\\nCleaned library data saved to 'output-data/cleaned_library_systembook.csv'\")\n",
    "\n",
    "# Display first few rows of cleaned data\n",
    "print(\"\\nFirst few rows of cleaned library data:\")\n",
    "print(df_library_cleaned.head())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLEANING COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
